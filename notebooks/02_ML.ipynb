{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "import logging\n",
    "import pickle\n",
    "import toml\n",
    "import os\n",
    "from typing import List, Union, Tuple\n",
    "import joblib\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    ConfusionMatrixDisplay,\n",
    ")\n",
    "\n",
    "import snowflake.connector\n",
    "from snowflake.snowpark.session import Session\n",
    "from snowflake.snowpark.functions import call_udf, array_construct, pandas_udf, col, udf\n",
    "\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from snowflake.snowpark import types as T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Connect to Snowflake\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(CURRENT_WAREHOUSE()='COMPUTE_WH', CURRENT_DATABASE()='HEART_DB', CURRENT_SCHEMA()='PUBLIC', CURRENT_USER()='JOANABAIAO', CURRENT_ROLE()='ACCOUNTADMIN')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = toml.load(\"../config.toml\")\n",
    "connection_parameters = config[\"snowflake_connection\"]\n",
    "session = Session.builder.configs(connection_parameters).create()\n",
    "\n",
    "# Check if the connection and database are correct:\n",
    "session.sql(\n",
    "    \"select current_warehouse(), current_database(), current_schema(), current_user(), current_role()\"\n",
    ").collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Training function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_model_to_stage(session, obj, model_stage, model_id):\n",
    "    \"\"\"Upload model to Snowflake stage\"\"\"\n",
    "\n",
    "    if not model_stage.startswith(\"@\"):\n",
    "        model_stage = f\"@{model_stage}\"\n",
    "\n",
    "    temp_file_path = os.path.join(\"/tmp\", model_id)\n",
    "    joblib.dump(obj, temp_file_path)\n",
    "    session.file.put(temp_file_path, model_stage, overwrite=True, auto_compress=False)\n",
    "    os.remove(temp_file_path)\n",
    "\n",
    "    print(f\"File '{model_id}' uploaded successfully to stage '{model_stage}'.\")\n",
    "\n",
    "\n",
    "def load_model_from_stage(session, model_stage, model_id):\n",
    "    \"\"\"Load model from Snowflake stage\"\"\"\n",
    "\n",
    "    if not model_stage.startswith(\"@\"):\n",
    "        model_stage = f\"@{model_stage}\"\n",
    "\n",
    "    file_path = f\"{model_stage}/{model_id}\"\n",
    "    local_path = f\"/tmp/{model_id}\"\n",
    "\n",
    "    session.file.get(file_path, \"/tmp/\")\n",
    "    model = joblib.load(local_path)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def deploy_model_as_udf(\n",
    "    session: Session,\n",
    "    model,\n",
    "    scaler,\n",
    "    model_id: str,\n",
    "    model_stage: str,\n",
    "    function_stage: str,\n",
    "    required_packages: List[str],\n",
    "):\n",
    "    \"\"\"\n",
    "    Deploy trained model and scaler as a permanent UDF\n",
    "    \"\"\"\n",
    "\n",
    "    scaler_id = f\"{model_id}_scaler\"\n",
    "    upload_model_to_stage(session, scaler, model_stage, scaler_id)\n",
    "    upload_model_to_stage(session, model, model_stage, model_id)\n",
    "\n",
    "    # Create the prediction function\n",
    "    def predict(features: list) -> float:\n",
    "        features_array = np.array(features).reshape(1, -1)\n",
    "        scaled_features = scaler.transform(features_array)\n",
    "        return float(model.predict(scaled_features)[0])\n",
    "\n",
    "    # Register as permanent UDF\n",
    "    udf_name = f\"PREDICT_{model_id}\"\n",
    "    session.udf.register(\n",
    "        func=predict,\n",
    "        name=udf_name,\n",
    "        stage_location=f\"@{function_stage}\",\n",
    "        is_permanent=True,\n",
    "        packages=required_packages,\n",
    "        imports=[f\"@{model_stage}/{model_id}\", f\"@{model_stage}/{scaler_id}\"],\n",
    "    )\n",
    "\n",
    "    print(f\"Successfully deployed model as UDF: {udf_name}\")\n",
    "    return udf_name\n",
    "\n",
    "\n",
    "def evaluate_model(y_test, y_pred):\n",
    "\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    TN, FP, FN, TP = conf_matrix.ravel()\n",
    "\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"precision\": precision_score(y_test, y_pred),\n",
    "        \"recall\": recall_score(y_test, y_pred),\n",
    "        \"f1\": f1_score(y_test, y_pred),\n",
    "        \"auc_roc\": roc_auc_score(y_test, y_pred),\n",
    "        \"TN\": TN,\n",
    "        \"FP\": FP,\n",
    "        \"FN\": FN,\n",
    "        \"TP\": TP,\n",
    "    }\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def save_training_info(\n",
    "    session,\n",
    "    model_id,\n",
    "    model_name,\n",
    "    optimization,\n",
    "    training_table,\n",
    "    feature_columns,\n",
    "    metrics,\n",
    "    table_name=\"MODEL_TRAINING_INFO\",\n",
    "):\n",
    "    from datetime import datetime\n",
    "\n",
    "    try:\n",
    "        training_date = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "        # training_date = str(datetime.datetime.now())\n",
    "        feature_columns_str = \",\".join([f\"'{col}'\" for col in feature_columns])\n",
    "\n",
    "        insert_query = f\"\"\"\n",
    "                INSERT INTO {table_name} (\n",
    "                training_date,\n",
    "                model_id,\n",
    "                model_name,\n",
    "                optimization,\n",
    "                training_table,\n",
    "                feature_columns,\n",
    "                accuracy, precision, recall, f1_score, auc_roc,\n",
    "                TN, FP, FN, TP\n",
    "            )\n",
    "            SELECT \n",
    "                '{training_date}', \n",
    "                '{model_id}', \n",
    "                '{model_name}', \n",
    "                {optimization}, \n",
    "                '{training_table}', \n",
    "                ARRAY_CONSTRUCT({feature_columns_str}),\n",
    "                {metrics['accuracy']}, {metrics['precision']}, {metrics['recall']},\n",
    "                {metrics['f1']}, {metrics['auc_roc']},\n",
    "                {metrics['TN']}, {metrics['FP']}, {metrics['FN']}, {metrics['TP']};\n",
    "            \"\"\"\n",
    "\n",
    "        session.sql(insert_query).collect()\n",
    "        print(f\"Training details for model '{model_id}' have been successfully logged.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error logging training details for model '{model_id}': {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_deploy_model(\n",
    "    session: Session,\n",
    "    model_name: str,\n",
    "    optimize: bool,\n",
    "    training_table: str,\n",
    ") -> dict:\n",
    "\n",
    "    ##########################\n",
    "    # IMPORTS\n",
    "    ##########################\n",
    "    import optuna\n",
    "    from sklearn.model_selection import train_test_split, cross_val_score\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.svm import SVC\n",
    "    from xgboost import XGBClassifier\n",
    "\n",
    "    model_abbreviations = {\n",
    "        \"Random Forest\": \"RF\",\n",
    "        \"XGBoost\": \"XGB\",\n",
    "        \"K-Nearest Neighbors\": \"KNN\",\n",
    "        \"Support Vector Machine\": \"SVM\",\n",
    "    }\n",
    "\n",
    "    ##########################\n",
    "    # FUNCTIONS AND VARIABLES\n",
    "    ##########################\n",
    "    python_packages = [\n",
    "        \"pandas==2.2.3\",\n",
    "        \"scikit-learn==1.5.2\",\n",
    "        \"xgboost==1.7.3\",\n",
    "    ]\n",
    "\n",
    "    ##########################\n",
    "    # STEP 1: LOAD TABLE DATA\n",
    "    ##########################\n",
    "    # Generate a unique model name using sequence from the database\n",
    "    seq_value = str(session.sql(\"select MODEL_SEQ.nextval\").collect()[0][0])\n",
    "\n",
    "    model_reduced = model_abbreviations.get(model_name)\n",
    "    model_id = f\"{model_reduced}_{seq_value}\"\n",
    "    scaler_id = f\"{model_reduced}_{seq_value}_scaler\"\n",
    "\n",
    "    # Load the table\n",
    "    df = session.table(training_table).to_pandas()\n",
    "\n",
    "    ##########################\n",
    "    # Data Preprocessing\n",
    "    ##########################\n",
    "    # Separate target variable and features\n",
    "    X = df.drop(\"TARGET\", axis=1)\n",
    "    y = df[\"TARGET\"]\n",
    "    feature_columns = X.columns.to_numpy()\n",
    "\n",
    "    # Split dataset into training and test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    # Scale data\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    ##########################\n",
    "    # Model Training\n",
    "    ##########################\n",
    "    if optimize:\n",
    "\n",
    "        def objective(trial):\n",
    "            clf = None\n",
    "            # Define hyperparameters and initialise classifier\n",
    "            if model_reduced == \"RF\":\n",
    "                params = {\n",
    "                    \"max_depth\": trial.suggest_int(\"max_depth\", 2, 64),\n",
    "                    \"n_estimators\": trial.suggest_int(\"n_estimators\", 5, 100),\n",
    "                    \"max_samples\": trial.suggest_float(\"rf_max_samples\", 0.2, 1),\n",
    "                }\n",
    "                clf = RandomForestClassifier(**params, random_state=42)\n",
    "\n",
    "            elif model_reduced == \"XGB\":\n",
    "                params = {\n",
    "                    \"max_depth\": trial.suggest_int(\"max_depth\", 2, 20),\n",
    "                    \"n_estimators\": trial.suggest_int(\"n_estimators\", 10, 200),\n",
    "                    \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "                }\n",
    "                clf = XGBClassifier(**params, random_state=42)\n",
    "\n",
    "            elif model_reduced == \"KNN\":\n",
    "                params = {\n",
    "                    \"n_neighbors\": trial.suggest_int(\"n_neighbors\", 1, 30),\n",
    "                }\n",
    "                clf = KNeighborsClassifier(**params)\n",
    "\n",
    "            elif model_reduced == \"SVM\":\n",
    "                params = {\n",
    "                    \"C\": trial.suggest_float(\"C\", 1e-5, 1e5),\n",
    "                    \"gamma\": trial.suggest_float(\"gamma\", 1e-5, 1e2),\n",
    "                }\n",
    "                clf = SVC(**params, random_state=42, probability=True)\n",
    "\n",
    "            elif model_reduced == \"LR\":\n",
    "                params = {\n",
    "                    \"C\": trial.suggest_loguniform(\"C\", 1e-4, 1e2),\n",
    "                    \"penalty\": trial.suggest_categorical(\"penalty\", [\"l1\", \"l2\"]),\n",
    "                }\n",
    "                clf = LogisticRegression(**params)\n",
    "\n",
    "            else:\n",
    "                raise ValueError(\"Invalid model_name value.\")\n",
    "\n",
    "            # Evaluate using cross-validation\n",
    "            score = cross_val_score(\n",
    "                clf, X_train_scaled, y_train, cv=3, scoring=\"roc_auc\"\n",
    "            ).mean()\n",
    "\n",
    "            # Attach the classifier to the trial\n",
    "            trial.set_user_attr(key=\"best_model\", value=clf)\n",
    "\n",
    "            return score\n",
    "\n",
    "        def callback(study, trial):\n",
    "            if study.best_trial.number == trial.number:\n",
    "                study.set_user_attr(\n",
    "                    key=\"best_model\", value=trial.user_attrs[\"best_model\"]\n",
    "                )\n",
    "\n",
    "        # Find best model\n",
    "        study = optuna.create_study(\n",
    "            direction=\"maximize\", sampler=optuna.samplers.RandomSampler(seed=42)\n",
    "        )\n",
    "\n",
    "        study.optimize(objective, n_trials=100, callbacks=[callback])\n",
    "        best_trial = study.best_trial\n",
    "        classifier = best_trial.user_attrs[\"best_model\"]  # Best model\n",
    "\n",
    "    # Without optimization with Optuna\n",
    "    else:\n",
    "        if model_reduced == \"RF\":\n",
    "            classifier = RandomForestClassifier(random_state=42)\n",
    "        elif model_reduced == \"XGB\":\n",
    "            classifier = XGBClassifier(random_state=42)\n",
    "        elif model_reduced == \"KNN\":\n",
    "            classifier = KNeighborsClassifier(n_neighbors=10)\n",
    "        elif model_reduced == \"SVM\":\n",
    "            classifier = SVC(random_state=42)\n",
    "        elif model_reduced == \"LR\":\n",
    "            classifier = LogisticRegression(random_state=42)\n",
    "\n",
    "    # Fit the classifier in the training data and predict on the test data\n",
    "    classifier.fit(X_train_scaled, y_train)\n",
    "    y_pred = classifier.predict(X_test_scaled)\n",
    "\n",
    "    ##########################\n",
    "    # Model Evaluation\n",
    "    ##########################\n",
    "    metrics = evaluate_model(y_test, y_pred)\n",
    "\n",
    "    ##################################\n",
    "    # SAVE MODELS AND RESULTS\n",
    "    ##################################\n",
    "    save_training_info(\n",
    "        session,\n",
    "        model_id,\n",
    "        model_name,\n",
    "        optimize,\n",
    "        training_table,\n",
    "        feature_columns,\n",
    "        metrics,\n",
    "    )\n",
    "\n",
    "    udf_name = deploy_model_as_udf(\n",
    "        session,\n",
    "        model=classifier,\n",
    "        scaler=scaler,\n",
    "        model_id=model_id,\n",
    "        model_stage=\"MODEL_STAGE\",\n",
    "        function_stage=\"FUNCTION_STAGE\",\n",
    "        required_packages=python_packages,\n",
    "    )\n",
    "\n",
    "    result = {\n",
    "        \"model_id\": model_id,\n",
    "        \"udf_name\": udf_name,\n",
    "    }\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-22 11:33:57,750] A new study created in memory with name: no-name-88f5ab33-877d-4844-a2a1-bb39437f8867\n",
      "[I 2025-01-22 11:33:58,033] Trial 0 finished with value: 0.9286946834482922 and parameters: {'max_depth': 9, 'n_estimators': 191, 'learning_rate': 0.22227824312530747}. Best is trial 0 with value: 0.9286946834482922.\n",
      "[I 2025-01-22 11:33:58,130] Trial 1 finished with value: 0.918216438724154 and parameters: {'max_depth': 13, 'n_estimators': 39, 'learning_rate': 0.055238410897498764}. Best is trial 0 with value: 0.9286946834482922.\n",
      "[I 2025-01-22 11:33:58,272] Trial 2 finished with value: 0.9233166623211421 and parameters: {'max_depth': 3, 'n_estimators': 175, 'learning_rate': 0.18432335340553055}. Best is trial 0 with value: 0.9286946834482922.\n",
      "[I 2025-01-22 11:33:58,323] Trial 3 finished with value: 0.9201817219338374 and parameters: {'max_depth': 15, 'n_estimators': 13, 'learning_rate': 0.29127385712697834}. Best is trial 0 with value: 0.9286946834482922.\n",
      "[I 2025-01-22 11:33:58,423] Trial 4 finished with value: 0.922580767498637 and parameters: {'max_depth': 17, 'n_estimators': 50, 'learning_rate': 0.06272924049005918}. Best is trial 0 with value: 0.9286946834482922.\n",
      "[I 2025-01-22 11:33:58,514] Trial 5 finished with value: 0.9181154645365694 and parameters: {'max_depth': 5, 'n_estimators': 68, 'learning_rate': 0.16217936517334897}. Best is trial 0 with value: 0.9286946834482922.\n",
      "[I 2025-01-22 11:33:58,608] Trial 6 finished with value: 0.9221831915112154 and parameters: {'max_depth': 10, 'n_estimators': 65, 'learning_rate': 0.18743733946949004}. Best is trial 0 with value: 0.9286946834482922.\n",
      "[I 2025-01-22 11:33:58,695] Trial 7 finished with value: 0.9197397425869301 and parameters: {'max_depth': 4, 'n_estimators': 65, 'learning_rate': 0.11624493455517058}. Best is trial 0 with value: 0.9286946834482922.\n",
      "[I 2025-01-22 11:33:58,879] Trial 8 finished with value: 0.9277593685557847 and parameters: {'max_depth': 10, 'n_estimators': 159, 'learning_rate': 0.06790539682592432}. Best is trial 0 with value: 0.9286946834482922.\n",
      "[I 2025-01-22 11:33:59,052] Trial 9 finished with value: 0.9223995196220184 and parameters: {'max_depth': 11, 'n_estimators': 123, 'learning_rate': 0.02347061968879934}. Best is trial 0 with value: 0.9286946834482922.\n",
      "[I 2025-01-22 11:33:59,161] Trial 10 finished with value: 0.894178814382896 and parameters: {'max_depth': 13, 'n_estimators': 42, 'learning_rate': 0.02886496196573106}. Best is trial 0 with value: 0.9286946834482922.\n",
      "[I 2025-01-22 11:33:59,339] Trial 11 finished with value: 0.9289607875670592 and parameters: {'max_depth': 20, 'n_estimators': 194, 'learning_rate': 0.24443523095377373}. Best is trial 11 with value: 0.9289607875670592.\n",
      "[I 2025-01-22 11:33:59,508] Trial 12 finished with value: 0.9256428610933339 and parameters: {'max_depth': 7, 'n_estimators': 28, 'learning_rate': 0.2084275776885255}. Best is trial 11 with value: 0.9289607875670592.\n",
      "[I 2025-01-22 11:33:59,637] Trial 13 finished with value: 0.9258887387707696 and parameters: {'max_depth': 10, 'n_estimators': 33, 'learning_rate': 0.15360130393226834}. Best is trial 11 with value: 0.9289607875670592.\n",
      "[I 2025-01-22 11:33:59,776] Trial 14 finished with value: 0.9096432719429236 and parameters: {'max_depth': 2, 'n_estimators': 183, 'learning_rate': 0.0850461946640049}. Best is trial 11 with value: 0.9289607875670592.\n",
      "[I 2025-01-22 11:33:59,867] Trial 15 finished with value: 0.9219589624467673 and parameters: {'max_depth': 14, 'n_estimators': 69, 'learning_rate': 0.16081972614156514}. Best is trial 11 with value: 0.9289607875670592.\n",
      "[I 2025-01-22 11:33:59,940] Trial 16 finished with value: 0.9264241073897619 and parameters: {'max_depth': 12, 'n_estimators': 45, 'learning_rate': 0.291179542051722}. Best is trial 11 with value: 0.9289607875670592.\n",
      "[I 2025-01-22 11:34:00,100] Trial 17 finished with value: 0.9291752194489874 and parameters: {'max_depth': 16, 'n_estimators': 189, 'learning_rate': 0.26949993162401814}. Best is trial 17 with value: 0.9291752194489874.\n",
      "[I 2025-01-22 11:34:00,330] Trial 18 finished with value: 0.928598133794749 and parameters: {'max_depth': 13, 'n_estimators': 186, 'learning_rate': 0.03566282559505665}. Best is trial 17 with value: 0.9291752194489874.\n",
      "[I 2025-01-22 11:34:00,377] Trial 19 finished with value: 0.9111597019760285 and parameters: {'max_depth': 5, 'n_estimators': 18, 'learning_rate': 0.10434579592134664}. Best is trial 17 with value: 0.9291752194489874.\n",
      "[I 2025-01-22 11:34:00,466] Trial 20 finished with value: 0.9292256275332433 and parameters: {'max_depth': 9, 'n_estimators': 61, 'learning_rate': 0.2503338776540595}. Best is trial 20 with value: 0.9292256275332433.\n",
      "[I 2025-01-22 11:34:00,562] Trial 21 finished with value: 0.9209229894048212 and parameters: {'max_depth': 8, 'n_estimators': 63, 'learning_rate': 0.16738186411589207}. Best is trial 20 with value: 0.9292256275332433.\n",
      "[I 2025-01-22 11:34:00,724] Trial 22 finished with value: 0.9195733485031643 and parameters: {'max_depth': 4, 'n_estimators': 163, 'learning_rate': 0.03161968666713354}. Best is trial 20 with value: 0.9292256275332433.\n",
      "[I 2025-01-22 11:34:00,913] Trial 23 finished with value: 0.9251757567138353 and parameters: {'max_depth': 20, 'n_estimators': 157, 'learning_rate': 0.06762754764491}. Best is trial 20 with value: 0.9292256275332433.\n",
      "[I 2025-01-22 11:34:01,030] Trial 24 finished with value: 0.9141209003926773 and parameters: {'max_depth': 2, 'n_estimators': 165, 'learning_rate': 0.21498862971580895}. Best is trial 20 with value: 0.9292256275332433.\n",
      "[I 2025-01-22 11:34:01,225] Trial 25 finished with value: 0.9261580032709947 and parameters: {'max_depth': 15, 'n_estimators': 157, 'learning_rate': 0.031472949002886205}. Best is trial 20 with value: 0.9292256275332433.\n",
      "[I 2025-01-22 11:34:01,295] Trial 26 finished with value: 0.9253502097703192 and parameters: {'max_depth': 8, 'n_estimators': 32, 'learning_rate': 0.26029999350392213}. Best is trial 20 with value: 0.9292256275332433.\n",
      "[I 2025-01-22 11:34:01,413] Trial 27 finished with value: 0.9156421500075059 and parameters: {'max_depth': 13, 'n_estimators': 73, 'learning_rate': 0.028431921582946856}. Best is trial 20 with value: 0.9292256275332433.\n",
      "[I 2025-01-22 11:34:01,511] Trial 28 finished with value: 0.9311363941627754 and parameters: {'max_depth': 7, 'n_estimators': 72, 'learning_rate': 0.22158579171803858}. Best is trial 28 with value: 0.9311363941627754.\n",
      "[I 2025-01-22 11:34:01,765] Trial 29 finished with value: 0.9242703074261063 and parameters: {'max_depth': 14, 'n_estimators': 179, 'learning_rate': 0.1469423282969653}. Best is trial 28 with value: 0.9311363941627754.\n",
      "[I 2025-01-22 11:34:01,939] Trial 30 finished with value: 0.9184179130421041 and parameters: {'max_depth': 4, 'n_estimators': 146, 'learning_rate': 0.23062766409890026}. Best is trial 28 with value: 0.9311363941627754.\n",
      "[I 2025-01-22 11:34:02,249] Trial 31 finished with value: 0.9288907851177637 and parameters: {'max_depth': 12, 'n_estimators': 157, 'learning_rate': 0.1532007229456733}. Best is trial 28 with value: 0.9311363941627754.\n",
      "[I 2025-01-22 11:34:02,438] Trial 32 finished with value: 0.904156928741299 and parameters: {'max_depth': 11, 'n_estimators': 91, 'learning_rate': 0.017371546755787604}. Best is trial 28 with value: 0.9311363941627754.\n",
      "[I 2025-01-22 11:34:02,502] Trial 33 finished with value: 0.9170768841799205 and parameters: {'max_depth': 4, 'n_estimators': 16, 'learning_rate': 0.19455901926649632}. Best is trial 28 with value: 0.9311363941627754.\n",
      "[I 2025-01-22 11:34:02,637] Trial 34 finished with value: 0.9280052462332203 and parameters: {'max_depth': 7, 'n_estimators': 107, 'learning_rate': 0.27319427743856695}. Best is trial 28 with value: 0.9311363941627754.\n",
      "[I 2025-01-22 11:34:02,736] Trial 35 finished with value: 0.9290951037790262 and parameters: {'max_depth': 6, 'n_estimators': 88, 'learning_rate': 0.2291098301774841}. Best is trial 28 with value: 0.9311363941627754.\n",
      "[I 2025-01-22 11:34:02,799] Trial 36 finished with value: 0.9164543680422227 and parameters: {'max_depth': 6, 'n_estimators': 24, 'learning_rate': 0.09402792134499272}. Best is trial 28 with value: 0.9311363941627754.\n",
      "[I 2025-01-22 11:34:02,954] Trial 37 finished with value: 0.9133853216083181 and parameters: {'max_depth': 5, 'n_estimators': 187, 'learning_rate': 0.2443549100736809}. Best is trial 28 with value: 0.9311363941627754.\n",
      "[I 2025-01-22 11:34:03,097] Trial 38 finished with value: 0.9270805186185972 and parameters: {'max_depth': 14, 'n_estimators': 176, 'learning_rate': 0.24306490230074318}. Best is trial 28 with value: 0.9311363941627754.\n",
      "[I 2025-01-22 11:34:03,250] Trial 39 finished with value: 0.9200011061335104 and parameters: {'max_depth': 5, 'n_estimators': 180, 'learning_rate': 0.1664092501555387}. Best is trial 28 with value: 0.9311363941627754.\n",
      "[I 2025-01-22 11:34:03,431] Trial 40 finished with value: 0.9275836513467176 and parameters: {'max_depth': 17, 'n_estimators': 181, 'learning_rate': 0.10222100774184051}. Best is trial 28 with value: 0.9311363941627754.\n",
      "[I 2025-01-22 11:34:03,504] Trial 41 finished with value: 0.9247378858628236 and parameters: {'max_depth': 4, 'n_estimators': 53, 'learning_rate': 0.13386125870161433}. Best is trial 28 with value: 0.9311363941627754.\n",
      "[I 2025-01-22 11:34:03,737] Trial 42 finished with value: 0.9171003500122464 and parameters: {'max_depth': 17, 'n_estimators': 174, 'learning_rate': 0.012016117854045303}. Best is trial 28 with value: 0.9311363941627754.\n",
      "[I 2025-01-22 11:34:03,863] Trial 43 finished with value: 0.9248557680912087 and parameters: {'max_depth': 11, 'n_estimators': 89, 'learning_rate': 0.07441126503651176}. Best is trial 28 with value: 0.9311363941627754.\n",
      "[I 2025-01-22 11:34:03,955] Trial 44 finished with value: 0.9228095791161994 and parameters: {'max_depth': 4, 'n_estimators': 74, 'learning_rate': 0.28344381413463055}. Best is trial 28 with value: 0.9311363941627754.\n",
      "[I 2025-01-22 11:34:04,109] Trial 45 finished with value: 0.9262311661017484 and parameters: {'max_depth': 8, 'n_estimators': 109, 'learning_rate': 0.21387549807960157}. Best is trial 28 with value: 0.9311363941627754.\n",
      "[I 2025-01-22 11:34:04,335] Trial 46 finished with value: 0.9229303056878965 and parameters: {'max_depth': 8, 'n_estimators': 195, 'learning_rate': 0.28910971553321224}. Best is trial 28 with value: 0.9311363941627754.\n",
      "[I 2025-01-22 11:34:04,582] Trial 47 finished with value: 0.9271208134821872 and parameters: {'max_depth': 6, 'n_estimators': 104, 'learning_rate': 0.09725470984686319}. Best is trial 28 with value: 0.9311363941627754.\n",
      "[I 2025-01-22 11:34:04,647] Trial 48 finished with value: 0.9169394075864957 and parameters: {'max_depth': 7, 'n_estimators': 17, 'learning_rate': 0.18677365685417008}. Best is trial 28 with value: 0.9311363941627754.\n",
      "[I 2025-01-22 11:34:04,720] Trial 49 finished with value: 0.9090114326799245 and parameters: {'max_depth': 11, 'n_estimators': 19, 'learning_rate': 0.09080747462861731}. Best is trial 28 with value: 0.9311363941627754.\n",
      "[I 2025-01-22 11:34:04,870] Trial 50 finished with value: 0.9212538813434782 and parameters: {'max_depth': 19, 'n_estimators': 55, 'learning_rate': 0.05201951290645469}. Best is trial 28 with value: 0.9311363941627754.\n",
      "[I 2025-01-22 11:34:05,233] Trial 51 finished with value: 0.9266420156912938 and parameters: {'max_depth': 11, 'n_estimators': 198, 'learning_rate': 0.0801960287383351}. Best is trial 28 with value: 0.9311363941627754.\n",
      "[I 2025-01-22 11:34:05,535] Trial 52 finished with value: 0.9220891701628386 and parameters: {'max_depth': 14, 'n_estimators': 155, 'learning_rate': 0.0789148877577959}. Best is trial 28 with value: 0.9311363941627754.\n",
      "[I 2025-01-22 11:34:05,907] Trial 53 finished with value: 0.9272418560920302 and parameters: {'max_depth': 15, 'n_estimators': 80, 'learning_rate': 0.19336869087213804}. Best is trial 28 with value: 0.9311363941627754.\n",
      "[I 2025-01-22 11:34:06,179] Trial 54 finished with value: 0.9276402221748166 and parameters: {'max_depth': 14, 'n_estimators': 112, 'learning_rate': 0.03618403331577841}. Best is trial 28 with value: 0.9311363941627754.\n",
      "[I 2025-01-22 11:34:06,380] Trial 55 finished with value: 0.9320073952926117 and parameters: {'max_depth': 17, 'n_estimators': 71, 'learning_rate': 0.06409036801595772}. Best is trial 55 with value: 0.9320073952926117.\n",
      "[I 2025-01-22 11:34:06,544] Trial 56 finished with value: 0.9141758910300473 and parameters: {'max_depth': 2, 'n_estimators': 122, 'learning_rate': 0.20649366493426188}. Best is trial 55 with value: 0.9320073952926117.\n",
      "[I 2025-01-22 11:34:06,644] Trial 57 finished with value: 0.9033503203836704 and parameters: {'max_depth': 2, 'n_estimators': 107, 'learning_rate': 0.075683774807402}. Best is trial 55 with value: 0.9320073952926117.\n",
      "[I 2025-01-22 11:34:06,729] Trial 58 finished with value: 0.9211187750361468 and parameters: {'max_depth': 14, 'n_estimators': 43, 'learning_rate': 0.21037194404971513}. Best is trial 55 with value: 0.9320073952926117.\n",
      "[I 2025-01-22 11:34:06,988] Trial 59 finished with value: 0.9282792513056326 and parameters: {'max_depth': 9, 'n_estimators': 188, 'learning_rate': 0.04988107380233804}. Best is trial 55 with value: 0.9320073952926117.\n",
      "[I 2025-01-22 11:34:07,058] Trial 60 finished with value: 0.9243085480417487 and parameters: {'max_depth': 8, 'n_estimators': 31, 'learning_rate': 0.2781611493007832}. Best is trial 55 with value: 0.9320073952926117.\n",
      "[I 2025-01-22 11:34:07,159] Trial 61 finished with value: 0.9239993047160793 and parameters: {'max_depth': 18, 'n_estimators': 59, 'learning_rate': 0.20139537334991192}. Best is trial 55 with value: 0.9320073952926117.\n",
      "[I 2025-01-22 11:34:07,476] Trial 62 finished with value: 0.9294722953060434 and parameters: {'max_depth': 17, 'n_estimators': 116, 'learning_rate': 0.1635986677232419}. Best is trial 55 with value: 0.9320073952926117.\n",
      "[I 2025-01-22 11:34:07,574] Trial 63 finished with value: 0.9238927998609432 and parameters: {'max_depth': 6, 'n_estimators': 27, 'learning_rate': 0.2701925698064647}. Best is trial 55 with value: 0.9320073952926117.\n",
      "[I 2025-01-22 11:34:07,777] Trial 64 finished with value: 0.9249703319190625 and parameters: {'max_depth': 19, 'n_estimators': 130, 'learning_rate': 0.10831863940412319}. Best is trial 55 with value: 0.9320073952926117.\n",
      "[I 2025-01-22 11:34:07,914] Trial 65 finished with value: 0.9240672529174271 and parameters: {'max_depth': 8, 'n_estimators': 148, 'learning_rate': 0.27016197538624737}. Best is trial 55 with value: 0.9320073952926117.\n",
      "[I 2025-01-22 11:34:08,064] Trial 66 finished with value: 0.9272002970758569 and parameters: {'max_depth': 18, 'n_estimators': 158, 'learning_rate': 0.19618917738474345}. Best is trial 55 with value: 0.9320073952926117.\n",
      "[I 2025-01-22 11:34:08,124] Trial 67 finished with value: 0.9349975902091382 and parameters: {'max_depth': 3, 'n_estimators': 40, 'learning_rate': 0.270580714672853}. Best is trial 67 with value: 0.9349975902091382.\n",
      "[I 2025-01-22 11:34:08,166] Trial 68 finished with value: 0.8432925644125246 and parameters: {'max_depth': 13, 'n_estimators': 11, 'learning_rate': 0.03942674743114931}. Best is trial 67 with value: 0.9349975902091382.\n",
      "[I 2025-01-22 11:34:08,207] Trial 69 finished with value: 0.8480793571784115 and parameters: {'max_depth': 14, 'n_estimators': 10, 'learning_rate': 0.056634334911074606}. Best is trial 67 with value: 0.9349975902091382.\n",
      "[I 2025-01-22 11:34:08,344] Trial 70 finished with value: 0.9271547875828613 and parameters: {'max_depth': 12, 'n_estimators': 142, 'learning_rate': 0.19906876525575415}. Best is trial 67 with value: 0.9349975902091382.\n",
      "[I 2025-01-22 11:34:08,503] Trial 71 finished with value: 0.9256583469624785 and parameters: {'max_depth': 6, 'n_estimators': 146, 'learning_rate': 0.07880223537407201}. Best is trial 67 with value: 0.9349975902091382.\n",
      "[I 2025-01-22 11:34:08,644] Trial 72 finished with value: 0.9247337773669283 and parameters: {'max_depth': 8, 'n_estimators': 152, 'learning_rate': 0.19839354072369225}. Best is trial 67 with value: 0.9349975902091382.\n",
      "[I 2025-01-22 11:34:08,776] Trial 73 finished with value: 0.9275413022351798 and parameters: {'max_depth': 18, 'n_estimators': 135, 'learning_rate': 0.17480949496728676}. Best is trial 67 with value: 0.9349975902091382.\n",
      "[I 2025-01-22 11:34:08,856] Trial 74 finished with value: 0.9260559229499 and parameters: {'max_depth': 3, 'n_estimators': 80, 'learning_rate': 0.08690868662770036}. Best is trial 67 with value: 0.9349975902091382.\n",
      "[I 2025-01-22 11:34:09,127] Trial 75 finished with value: 0.9256001959436504 and parameters: {'max_depth': 6, 'n_estimators': 195, 'learning_rate': 0.1239983401533605}. Best is trial 67 with value: 0.9349975902091382.\n",
      "[I 2025-01-22 11:34:09,246] Trial 76 finished with value: 0.931923013107682 and parameters: {'max_depth': 18, 'n_estimators': 130, 'learning_rate': 0.24049527802707804}. Best is trial 67 with value: 0.9349975902091382.\n",
      "[I 2025-01-22 11:34:09,375] Trial 77 finished with value: 0.9283936571144137 and parameters: {'max_depth': 11, 'n_estimators': 120, 'learning_rate': 0.15283013120747052}. Best is trial 67 with value: 0.9349975902091382.\n",
      "[I 2025-01-22 11:34:09,546] Trial 78 finished with value: 0.9202117455576887 and parameters: {'max_depth': 5, 'n_estimators': 147, 'learning_rate': 0.09142398510784817}. Best is trial 67 with value: 0.9349975902091382.\n",
      "[I 2025-01-22 11:34:09,648] Trial 79 finished with value: 0.904324033910893 and parameters: {'max_depth': 2, 'n_estimators': 133, 'learning_rate': 0.06136209702804419}. Best is trial 67 with value: 0.9349975902091382.\n",
      "[I 2025-01-22 11:34:09,798] Trial 80 finished with value: 0.9238409696050313 and parameters: {'max_depth': 19, 'n_estimators': 192, 'learning_rate': 0.27531067316393004}. Best is trial 67 with value: 0.9349975902091382.\n",
      "[I 2025-01-22 11:34:09,851] Trial 81 finished with value: 0.9225458452835257 and parameters: {'max_depth': 9, 'n_estimators': 12, 'learning_rate': 0.27921238315044034}. Best is trial 67 with value: 0.9349975902091382.\n",
      "[I 2025-01-22 11:34:09,996] Trial 82 finished with value: 0.919641612742658 and parameters: {'max_depth': 10, 'n_estimators': 194, 'learning_rate': 0.28944979335588333}. Best is trial 67 with value: 0.9349975902091382.\n",
      "[I 2025-01-22 11:34:10,092] Trial 83 finished with value: 0.9232213768201821 and parameters: {'max_depth': 18, 'n_estimators': 66, 'learning_rate': 0.12167834129455832}. Best is trial 67 with value: 0.9349975902091382.\n",
      "[I 2025-01-22 11:34:10,215] Trial 84 finished with value: 0.9305567802033705 and parameters: {'max_depth': 18, 'n_estimators': 70, 'learning_rate': 0.05915289653896682}. Best is trial 67 with value: 0.9349975902091382.\n",
      "[I 2025-01-22 11:34:10,378] Trial 85 finished with value: 0.9186726397876223 and parameters: {'max_depth': 12, 'n_estimators': 188, 'learning_rate': 0.21184864103574216}. Best is trial 67 with value: 0.9349975902091382.\n",
      "[I 2025-01-22 11:34:10,443] Trial 86 finished with value: 0.9215386317128478 and parameters: {'max_depth': 12, 'n_estimators': 28, 'learning_rate': 0.1883520957427592}. Best is trial 67 with value: 0.9349975902091382.\n",
      "[I 2025-01-22 11:34:10,512] Trial 87 finished with value: 0.9260271634786319 and parameters: {'max_depth': 20, 'n_estimators': 36, 'learning_rate': 0.16031559918548366}. Best is trial 67 with value: 0.9349975902091382.\n",
      "[I 2025-01-22 11:34:10,665] Trial 88 finished with value: 0.9188298687651599 and parameters: {'max_depth': 18, 'n_estimators': 151, 'learning_rate': 0.2121345648886277}. Best is trial 67 with value: 0.9349975902091382.\n",
      "[I 2025-01-22 11:34:10,779] Trial 89 finished with value: 0.929118016544597 and parameters: {'max_depth': 15, 'n_estimators': 78, 'learning_rate': 0.09514163483670307}. Best is trial 67 with value: 0.9349975902091382.\n",
      "[I 2025-01-22 11:34:10,930] Trial 90 finished with value: 0.9275299248619309 and parameters: {'max_depth': 17, 'n_estimators': 164, 'learning_rate': 0.26145097238823006}. Best is trial 67 with value: 0.9349975902091382.\n",
      "[I 2025-01-22 11:34:11,052] Trial 91 finished with value: 0.921094282079847 and parameters: {'max_depth': 19, 'n_estimators': 107, 'learning_rate': 0.1554397254592879}. Best is trial 67 with value: 0.9349975902091382.\n",
      "[I 2025-01-22 11:34:11,189] Trial 92 finished with value: 0.9224973334281449 and parameters: {'max_depth': 17, 'n_estimators': 134, 'learning_rate': 0.21357039440473397}. Best is trial 67 with value: 0.9349975902091382.\n",
      "[I 2025-01-22 11:34:11,374] Trial 93 finished with value: 0.9316273594222823 and parameters: {'max_depth': 17, 'n_estimators': 179, 'learning_rate': 0.10801859548694537}. Best is trial 67 with value: 0.9349975902091382.\n",
      "[I 2025-01-22 11:34:11,440] Trial 94 finished with value: 0.9269863392511476 and parameters: {'max_depth': 9, 'n_estimators': 27, 'learning_rate': 0.17770124088889044}. Best is trial 67 with value: 0.9349975902091382.\n",
      "[I 2025-01-22 11:34:11,525] Trial 95 finished with value: 0.9091965520238293 and parameters: {'max_depth': 2, 'n_estimators': 98, 'learning_rate': 0.16736694406519723}. Best is trial 67 with value: 0.9349975902091382.\n",
      "[I 2025-01-22 11:34:11,697] Trial 96 finished with value: 0.9175706147732031 and parameters: {'max_depth': 7, 'n_estimators': 122, 'learning_rate': 0.018845072482324334}. Best is trial 67 with value: 0.9349975902091382.\n",
      "[I 2025-01-22 11:34:11,814] Trial 97 finished with value: 0.9135055741227966 and parameters: {'max_depth': 2, 'n_estimators': 167, 'learning_rate': 0.11445528600926623}. Best is trial 67 with value: 0.9349975902091382.\n",
      "[I 2025-01-22 11:34:11,924] Trial 98 finished with value: 0.919956386735879 and parameters: {'max_depth': 4, 'n_estimators': 109, 'learning_rate': 0.23329813039859715}. Best is trial 67 with value: 0.9349975902091382.\n",
      "[I 2025-01-22 11:34:12,185] Trial 99 finished with value: 0.9309052122591197 and parameters: {'max_depth': 6, 'n_estimators': 128, 'learning_rate': 0.03475076484819272}. Best is trial 67 with value: 0.9349975902091382.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training details for model 'XGB_101' have been successfully logged.\n",
      "File 'XGB_101_scaler' uploaded successfully to stage '@MODEL_STAGE'.\n",
      "File 'XGB_101' uploaded successfully to stage '@MODEL_STAGE'.\n",
      "Successfully deployed model as UDF: PREDICT_XGB_101\n",
      "CPU times: user 1min 34s, sys: 3.79 s, total: 1min 37s\n",
      "Wall time: 21.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_id': 'XGB_101', 'udf_name': 'PREDICT_XGB_101'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_and_deploy_model(session, model_name=\"XGBoost\", optimize=True, training_table=\"DATA_TABLE_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(name='model_stage/XGB_101', size=48032, md5='4f5757fa031b4dff58b59d49adc8ec9b', last_modified='Wed, 22 Jan 2025 11:34:14 GMT'),\n",
       " Row(name='model_stage/XGB_101_scaler', size=1360, md5='52da28936711b10b53f04a52a2a438e4', last_modified='Wed, 22 Jan 2025 11:34:14 GMT')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.sql(\"ls @MODEL_STAGE\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TRAINING_DATE</th>\n",
       "      <th>MODEL_ID</th>\n",
       "      <th>MODEL_NAME</th>\n",
       "      <th>OPTIMIZATION</th>\n",
       "      <th>TRAINING_TABLE</th>\n",
       "      <th>FEATURE_COLUMNS</th>\n",
       "      <th>ACCURACY</th>\n",
       "      <th>PRECISION</th>\n",
       "      <th>RECALL</th>\n",
       "      <th>F1_SCORE</th>\n",
       "      <th>AUC_ROC</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-01-22 11:34:12</td>\n",
       "      <td>XGB_101</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>True</td>\n",
       "      <td>DATA_TABLE_1</td>\n",
       "      <td>[\\n  \"AGE\",\\n  \"SEX\",\\n  \"CP\",\\n  \"TRESTBPS\",\\...</td>\n",
       "      <td>0.942029</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.941426</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        TRAINING_DATE MODEL_ID MODEL_NAME  OPTIMIZATION TRAINING_TABLE  \\\n",
       "0 2025-01-22 11:34:12  XGB_101    XGBoost          True   DATA_TABLE_1   \n",
       "\n",
       "                                     FEATURE_COLUMNS  ACCURACY  PRECISION  \\\n",
       "0  [\\n  \"AGE\",\\n  \"SEX\",\\n  \"CP\",\\n  \"TRESTBPS\",\\...  0.942029   0.947368   \n",
       "\n",
       "     RECALL  F1_SCORE   AUC_ROC  TN  FP  FN  TP  \n",
       "0  0.947368  0.947368  0.941426  29   2   2  36  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_training_info = session.table(\"MODEL_TRAINING_INFO\").to_pandas()\n",
    "df_training_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Register</b> the function as a <b>Stored Procedure</b> within Snowflake\n",
    "This will push down all the function and dependencies into Snowflake.\n",
    "Once the SP is being defined, we can call it directly from Snowflake without the need of a notebook.\n",
    "For example it can be called from a Task to trigger a new training based on new data.\n",
    "\n",
    "Because <b>optuna</b> and <b>cmaes</b> libraries are not included in the Anaconda repository, we are going to add them from the local repository. We get the local path and we will include it later in the imports section when registering the functions as Stored Procedures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.snowpark.stored_procedure.StoredProcedure at 0x1468f7710>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optuna_path = optuna.__path__[0]\n",
    "\n",
    "session.sproc.register(\n",
    "    func=train_and_deploy_model,\n",
    "    name=\"train_and_deploy_model\",\n",
    "    packages=[\n",
    "        \"snowflake-snowpark-python\",\n",
    "        \"scikit-learn==1.5.2\",\n",
    "        \"xgboost==1.7.3\",\n",
    "        \"sqlalchemy==1.4.39\",\n",
    "        \"tqdm==4.64.1\",\n",
    "        \"colorlog==5.0.1\",\n",
    "    ],\n",
    "    imports=[optuna_path],\n",
    "    is_permanent=True,\n",
    "    stage_location=\"@FUNCTION_STAGE\",\n",
    "    replace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test now the Stored Procedure for training executed within Snowflake\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"model_id\": \"XGB_102\",\\n  \"udf_name\": \"PREDICT_XGB_102\"\\n}'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"XGBoost\"\n",
    "optimization = True\n",
    "training_table = \"DATA_TABLE_2\"\n",
    "\n",
    "session.call(\n",
    "    \"train_and_deploy_model\",\n",
    "    model_name,\n",
    "    optimization,\n",
    "    training_table,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(name='model_stage/SVM_2', size=33584, md5='bdf5762f9f5a3b30f16913cf7df24918', last_modified='Tue, 21 Jan 2025 17:15:24 GMT'),\n",
       " Row(name='model_stage/SVM_2_scaler', size=1360, md5='fce1e5e5e248e89c6b1dd4d1973b9755', last_modified='Tue, 21 Jan 2025 17:15:24 GMT'),\n",
       " Row(name='model_stage/XGB_101', size=95856, md5='407b7b5f6391945a13f57753e50546a0', last_modified='Tue, 21 Jan 2025 17:45:50 GMT'),\n",
       " Row(name='model_stage/XGB_101_scaler', size=1360, md5='929db76dc27def46552fe33429ec9ee6', last_modified='Tue, 21 Jan 2025 17:45:50 GMT'),\n",
       " Row(name='model_stage/XGB_102', size=240896, md5='d33a37948de0d7e5ab29b20f5e42ee54', last_modified='Tue, 21 Jan 2025 17:47:20 GMT'),\n",
       " Row(name='model_stage/XGB_102_scaler', size=1360, md5='8e574d847fbdeb9ae3a09592e979d6c2', last_modified='Tue, 21 Jan 2025 17:47:19 GMT'),\n",
       " Row(name='model_stage/XGB_3', size=95856, md5='b9992a9f45c864106b9a3c4e1b7f2649', last_modified='Tue, 21 Jan 2025 17:16:53 GMT'),\n",
       " Row(name='model_stage/XGB_3_scaler', size=1360, md5='f398c89e06435ce975225c61ab21d16b', last_modified='Tue, 21 Jan 2025 17:16:53 GMT')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.sql(\"ls @MODEL_STAGE\").collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Run Inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_inference_details(\n",
    "    session,\n",
    "    model_id,\n",
    "    training_table,\n",
    "    test_table,\n",
    "    # predictions_table,\n",
    "    metrics,\n",
    "    table_name=\"INFERENCE_RESULTS\",\n",
    "):\n",
    "\n",
    "    from datetime import datetime\n",
    "\n",
    "    try:\n",
    "        inference_date = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        insert_query = f\"\"\"\n",
    "                INSERT INTO {table_name} (\n",
    "                    inference_date,\n",
    "                    model_id,\n",
    "                    training_table,\n",
    "                    test_table,\n",
    "                    accuracy, precision, recall, f1_score, auc_roc,\n",
    "                    TN, FP, FN, TP\n",
    "                )\n",
    "                VALUES (\n",
    "                    '{inference_date}',\n",
    "                    '{model_id}',\n",
    "                    '{training_table}',\n",
    "                    '{test_table}',\n",
    "                    {metrics['accuracy']}, {metrics['precision']}, {metrics['recall']},\n",
    "                    {metrics['f1']}, {metrics['auc_roc']},\n",
    "                    {metrics['TN']}, {metrics['FP']}, {metrics['FN']}, {metrics['TP']}\n",
    "                );\n",
    "                \"\"\"\n",
    "\n",
    "        session.sql(insert_query).collect()\n",
    "        print(f\"Inference details stored successfully for model {model_id}.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to store inference details: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference(\n",
    "    session: Session,\n",
    "    test_table: str,\n",
    "    model_id: str,\n",
    "    predictions_table: str = \"PREDICTIONS_RESULT\",\n",
    "    target_column: str = \"TARGET\",\n",
    ") -> None:\n",
    "\n",
    "    try:\n",
    "\n",
    "        query_result = session.sql(\n",
    "            f\"\"\"\n",
    "            SELECT FEATURE_COLUMNS, TRAINING_TABLE\n",
    "            FROM MODEL_TRAINING_INFO \n",
    "            WHERE MODEL_ID = '{model_id}'\n",
    "        \"\"\"\n",
    "        ).collect()\n",
    "\n",
    "        training_table = query_result[0][\"TRAINING_TABLE\"]\n",
    "        feature_columns = query_result[0][\"FEATURE_COLUMNS\"]\n",
    "        feature_columns = json.loads(feature_columns)\n",
    "        features_array = array_construct(*[col(c) for c in feature_columns])\n",
    "\n",
    "        # Get data\n",
    "        df = session.table(test_table)\n",
    "        has_target = target_column in df.columns\n",
    "\n",
    "        # Predict\n",
    "        df_predictions = df.select(\n",
    "            *feature_columns,\n",
    "            *([target_column] if has_target else []),\n",
    "            call_udf(f\"PREDICT_{model_id}\", features_array).alias(\"PREDICTION\"),\n",
    "        )\n",
    "\n",
    "        df_predictions.write.mode(\"overwrite\").save_as_table(predictions_table)\n",
    "        print(f\"Predictions saved in table {predictions_table}!\")\n",
    "\n",
    "        if has_target:\n",
    "            df_predictions_pd = df_predictions.to_pandas()\n",
    "            metrics = evaluate_model(\n",
    "                df_predictions_pd[target_column], df_predictions_pd[\"PREDICTION\"]\n",
    "            )\n",
    "\n",
    "            save_inference_details(\n",
    "                session,\n",
    "                model_id,\n",
    "                training_table,\n",
    "                test_table,\n",
    "                # predictions_table,\n",
    "                metrics,\n",
    "            )\n",
    "\n",
    "        return metrics\n",
    "\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Error in inference pipeline: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved in table PREDICTIONS_RESULT!\n",
      "Inference details stored successfully for model RF_201.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9824561403508771,\n",
       " 'precision': 0.9827586206896551,\n",
       " 'recall': 0.9827586206896551,\n",
       " 'f1': 0.9827586206896551,\n",
       " 'auc_roc': 0.9824507389162561,\n",
       " 'TN': 165,\n",
       " 'FP': 3,\n",
       " 'FN': 3,\n",
       " 'TP': 171}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_inference(session, test_table=\"DATA_TABLE_2\", model_id=\"RF_201\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snowflake.snowpark.stored_procedure.StoredProcedure at 0x146503a50>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.sproc.register(\n",
    "    func=run_inference,\n",
    "    name=\"run_inference\",\n",
    "    packages=[\n",
    "        \"snowflake-snowpark-python\",\n",
    "        \"scikit-learn==1.2.1\",\n",
    "        \"joblib==1.1.1\",\n",
    "        \"xgboost==1.7.3\",\n",
    "    ],\n",
    "    is_permanent=True,\n",
    "    stage_location=\"@FUNCTION_STAGE\",\n",
    "    replace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'accuracy': 0.9093567251461988, 'precision': 0.9090909090909091, 'recall': 0.9036144578313253, 'f1': 0.9063444108761329, 'auc_roc': 0.9091935925520264, 'TN': 161, 'FP': 15, 'FN': 16, 'TP': 150}\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.call(\"run_inference\", \"DATA_TABLE_3\", \"RF_201\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>CP</th>\n",
       "      <th>TRESTBPS</th>\n",
       "      <th>CHOL</th>\n",
       "      <th>FBS</th>\n",
       "      <th>RESTECG</th>\n",
       "      <th>THALACH</th>\n",
       "      <th>EXANG</th>\n",
       "      <th>OLDPEAK</th>\n",
       "      <th>SLOPE</th>\n",
       "      <th>CA</th>\n",
       "      <th>THAL</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>PREDICTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>120.0</td>\n",
       "      <td>219</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>140.0</td>\n",
       "      <td>185</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>160.0</td>\n",
       "      <td>201</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>248</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>239</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>206</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>135.0</td>\n",
       "      <td>250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>166</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130.0</td>\n",
       "      <td>256</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>342 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     AGE  SEX  CP  TRESTBPS  CHOL  FBS  RESTECG  THALACH  EXANG  OLDPEAK  \\\n",
       "0     50    0   2     120.0   219  0.0      1.0    158.0    0.0      1.6   \n",
       "1     40    1   0     152.0   223  0.0      1.0    181.0    0.0      0.0   \n",
       "2     60    1   2     140.0   185  0.0      0.0    155.0    0.0      3.0   \n",
       "3     54    0   2     160.0   201  0.0      1.0    163.0    0.0      0.0   \n",
       "4     65    1   0     110.0   248  0.0      0.0    158.0    0.0      0.6   \n",
       "..   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
       "337   59    1   0     110.0   239  0.0      0.0    142.0    1.0      1.2   \n",
       "338   60    1   0     130.0   206  0.0      0.0    132.0    1.0      2.4   \n",
       "339   55    0   1     135.0   250  0.0      0.0    161.0    0.0      1.4   \n",
       "340   61    1   0     138.0   166  0.0      0.0    125.0    1.0      3.6   \n",
       "341   56    1   2     130.0   256  1.0      0.0    142.0    1.0      0.6   \n",
       "\n",
       "     SLOPE   CA  THAL  TARGET  PREDICTION  \n",
       "0      1.0  0.0     2       1         1.0  \n",
       "1      2.0  0.0     3       0         1.0  \n",
       "2      1.0  0.0     2       0         0.0  \n",
       "3      2.0  1.0     2       1         1.0  \n",
       "4      2.0  2.0     1       0         0.0  \n",
       "..     ...  ...   ...     ...         ...  \n",
       "337    1.0  1.0     3       0         0.0  \n",
       "338    1.0  2.0     3       0         0.0  \n",
       "339    1.0  0.0     2       1         1.0  \n",
       "340    1.0  1.0     2       0         0.0  \n",
       "341    1.0  1.0     1       0         1.0  \n",
       "\n",
       "[342 rows x 15 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predictions_result = session.table(\"PREDICTIONS_RESULT\").to_pandas()\n",
    "df_predictions_result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snowpark_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
