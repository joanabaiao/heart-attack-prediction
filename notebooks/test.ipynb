{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import toml\n",
    "import snowflake.connector\n",
    "from snowflake.snowpark.session import Session\n",
    "from snowflake.snowpark.functions import call_udf, array_construct, pandas_udf, col, udf\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    ConfusionMatrixDisplay,\n",
    ")\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(CURRENT_WAREHOUSE()='COMPUTE_WH', CURRENT_DATABASE()='HEART_DB', CURRENT_SCHEMA()=None, CURRENT_USER()='JOANABAIAO', CURRENT_ROLE()='ACCOUNTADMIN')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = toml.load(\"../config.toml\")\n",
    "connection_parameters = config[\"snowflake_connection\"]\n",
    "session = Session.builder.configs(connection_parameters).create()\n",
    "\n",
    "# Check if the connection and database are correct:\n",
    "session.sql(\n",
    "    \"select current_warehouse(), current_database(), current_schema(), current_user(), current_role()\"\n",
    ").collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model (locally)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before implementing the training process within Snowflake, I first tested a simple machine learning model locally. For this initial experiment, I used the Random Forest classifier.\n",
    "\n",
    "The goal is to experiment with and fine-tune the model, ensuring that the chosen approach works effectively before integrating it into a Stored Procedure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>CP</th>\n",
       "      <th>TRESTBPS</th>\n",
       "      <th>CHOL</th>\n",
       "      <th>FBS</th>\n",
       "      <th>RESTECG</th>\n",
       "      <th>THALACH</th>\n",
       "      <th>EXANG</th>\n",
       "      <th>OLDPEAK</th>\n",
       "      <th>SLOPE</th>\n",
       "      <th>CA</th>\n",
       "      <th>THAL</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>177</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>156.0</td>\n",
       "      <td>245</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>105.0</td>\n",
       "      <td>240</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AGE  SEX  CP  TRESTBPS  CHOL  FBS  RESTECG  THALACH  EXANG  OLDPEAK  SLOPE  \\\n",
       "0   59    1   0     135.0   234  0.0      1.0    161.0    0.0      0.5    1.0   \n",
       "1   59    1   0     140.0   177  0.0      1.0    162.0    1.0      0.0    2.0   \n",
       "2   70    1   1     156.0   245  0.0      0.0    143.0    0.0      0.0    2.0   \n",
       "3   65    0   0     150.0   225  0.0      0.0    114.0    0.0      1.0    1.0   \n",
       "4   58    1   2     105.0   240  0.0      0.0    154.0    1.0      0.6    1.0   \n",
       "\n",
       "    CA  THAL  TARGET  \n",
       "0  0.0     3       1  \n",
       "1  1.0     3       0  \n",
       "2  0.0     2       1  \n",
       "3  3.0     3       0  \n",
       "4  0.0     3       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_name = \"DATA_TABLE_1\"\n",
    "df = session.table(table_name).to_pandas()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into train-test sets and scale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\"TARGET\", axis=1)\n",
    "y = df[\"TARGET\"]\n",
    "\n",
    "# Split dataset into training and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimization technique Optuna will be used to fine-tune hyperparameters and select the best model based on cross-validation results.\n",
    "\n",
    "**Steps:**\n",
    "\n",
    "1. Define the Optuna objective and callback functions\n",
    "2. Run the Optuna study\n",
    "3. Analyze results of the best trial\n",
    "\n",
    "**Calback function:** The callback function is triggered at the end of each trial. It checks if the current trial (trial) is the best trial using `study.best_trial.number == trial.number`. If true, it updates the study's user_attrs with the best model from the current trial.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    # Define hyperparameters and initialise classifier\n",
    "    params = {\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 64, log=True),\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 5, 50, log=True),\n",
    "        \"max_samples\": trial.suggest_float(\"rf_max_samples\", 0.2, 1),\n",
    "    }\n",
    "    classifier = RandomForestClassifier(**params, random_state=42)\n",
    "\n",
    "    # Evaluate using cross-validation\n",
    "    score = cross_val_score(\n",
    "        classifier, X_train_scaled, y_train, cv=3, scoring=\"roc_auc\"\n",
    "    ).mean()\n",
    "\n",
    "    # Attach the classifier to the trial\n",
    "    trial.set_user_attr(key=\"best_model\", value=classifier)\n",
    "\n",
    "    return score\n",
    "\n",
    "\n",
    "def callback(study, trial):\n",
    "    if study.best_trial.number == trial.number:\n",
    "        study.set_user_attr(key=\"best_model\", value=trial.user_attrs[\"best_model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(\n",
    "    direction=\"maximize\", sampler=optuna.samplers.RandomSampler(seed=42)\n",
    ")\n",
    "study.optimize(objective, n_trials=100, callbacks=[callback])\n",
    "\n",
    "print(\"Best Trial:\")\n",
    "best_trial = study.best_trial\n",
    "best_model = study.user_attrs[\"best_model\"]\n",
    "\n",
    "print(\"Best Score: \", best_trial.value)\n",
    "print(\"Best Params: \")\n",
    "for key, value in best_trial.params.items():\n",
    "    print(\"  {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets rebuild our classifier with the parameters from Optuna.\n",
    "\n",
    "The optimized model is trained on the entire training set and evaluated on the test set. Key metrics include:\n",
    "\n",
    "- Confusion matrix\n",
    "- Classification report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit best model\n",
    "best_trial = study.best_trial\n",
    "best_model = best_trial.user_attrs[\"best_model\"]\n",
    "best_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = best_model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "# Print the metrics\n",
    "print(\"Model Evaluation Metrics:\")\n",
    "print(f\"* Accuracy: {accuracy:.4f}\")\n",
    "print(f\"* Precision: {precision:.4f}\")\n",
    "print(f\"* Recall (Sensitivity): {recall:.4f}\")\n",
    "print(f\"* F1-Score: {f1:.4f}\")\n",
    "print(f\"* ROC AUC Score: {roc_auc:.4f}\")\n",
    "print()\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "TN, FP, FN, TP = conf_matrix.ravel()\n",
    "\n",
    "print(\"True Negative (TN):\", TN)\n",
    "print(\"False Positive (FP):\", FP)\n",
    "print(\"False Negative (FN):\", FN)\n",
    "print(\"True Positive (TP):\", TP)\n",
    "\n",
    "\n",
    "disp = ConfusionMatrixDisplay(\n",
    "    confusion_matrix=conf_matrix, display_labels=best_model.classes_\n",
    ")\n",
    "disp.plot(cmap=plt.cm.Blues, values_format=\"g\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the Optuna Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_parallel_coordinate(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study, params=[\"n_estimators\", \"max_depth\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snowpark_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
